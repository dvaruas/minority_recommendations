\section{Introduction}

Recommender systems are a common utility found in all social platforms today. It has become the dominant mechanism through which an individual can get connected to new people, products or events; can expand his/her own knowledge-base, or simply find new avenues for exploration within the given social space. As internet has grown the amount of information content flowing through the space is enormous, and finding relevant information has become a big challenge. Even with information being organized based on content, relevance ranking based on user preference is a big challenge which has been taken up by these recommendation systems \cite{rashid2002getting}.Of course this has enhanced the user experience in the platforms considerably and user engagement has been much higher \cite{pu2011user,konstan2012recommender}.

Research in this field was widely popularized by the Netflix Prize competition \cite{netflixprize2006} in 2006. Much of the research in literature has focused on content recommendation since the business aspect of it is quiet evident. However, another kind of recommendation engines are for recommending users which play a crucial role in the growth of social networks \cite{su2016effect,daly2010network,stoica2018algorithmic}. Today the most popular social network platforms like Facebook, Twitter, Instagram have recommendation agents as ``People you may know'', ``Who to Follow'', ``Suggested people''. Recommender systems in social networks, when suggesting links uses link prediction strategies derived from the network structure. It is unknown how most of the recommender systems work in these social networks, other than that of Twitter as given in their paper \cite{gupta2013wtf}. Most social network growth algorithms use friend-of-friend algorithms, or random walk models to predict links. These approaches have been quite common in research and has been extensively studied in \cite{backstrom2011supervised,chen2009make,gupta2013wtf}. At the heart of these systems lie the traidic closure concept from social sciences theories which was proposed by the German sociologist Georg Simmel \cite{simmel1950sociology}. The way the network grows under such recommendation algorithms has been analyzed in \cite{su2016effect}. The power-law construct with `rich-getting-richer' is an effect which can be seen with such recommender systems.

The crucial role recommender systems play in networks, have also borne ill effects. Mostly creating highly polarized networks, with the glass ceiling and echo chamber effects being prominent \cite{stoica2018algorithmic}. The ill effects of content recommendation can be often seen in multiple news sources \cite{youtubefeed2020,guardianselfharm,youtuberabbit2020}. The recommender systems are modeled to maximize user engagement, but the companies are trying to tweak their AI models to have better judgement and not be overtly biased to reaffirm biases from hyper-engaged users.

With respect to social networks, homophily as a parameter has been found to be relevant in shaping how network structures evolve \cite{dong2017structural,mcpherson2001birds}. The term homophily was introduced by Lazarsfeld et al. in their essay ``Friendship as a social process'' \cite{lazarsfeld1954friendship}. The essence of homophily can be well understood through the famous proverb \textit{``Birds of a feather flock together''}. This parameter tries to capture and  quantify the human instinct to bond with people who share common attributes with them. These attributes could be as varied as common race, age-group, gender along with common goals, ideologies or personalities. Humans being communal by nature tend to form communities and these aforementioned attributes are a way of building associations. Homophily in social structures, specially how these associations affect a given minority and majority group have been widely researched. It has been established through studies that these have varying effects on the evolving structure of a society, distribution of information and visibility of a certain group \cite{stoica2018algorithmic,avin2015homophily,mcpherson2001birds,karimi2018homophily}. 

As machine learning systems learn from user behavior, it can be expected that the intrinsic homophilic patters in humans behavior becomes a part of the algorithmic behavior too. Networks growing with the help of these biased systems would therefore imbibe this bias on the network structure itself. When a supposedly objective system would need to take some decision based on the parameters of these kind of evolved networks, it will fail to maintain it's objectivity due to the inherent bias the network possesses. Ranking systems are prevalent today to make decisions for `employability', `credit-score' or other services. These systems are supposed to objectively rank people based on certain parameters. These kind of systems would be affected by a biased model of the network. This forms the crux of our work, trying to understand how the agent aided growth (termed here as algorithmic growth) of a network is influenced by homophily of the users interacting with it. 

Our usage of reinforcement learning methods is stemmed from the fact that this branch of learning algorithms is widely gaining popularity due to the promising results it shows. Although there are multiple challenges currently in having a reinforcement learning agent function effectively in the real-world as studied in \cite{dulac2019challenges}, we can expect to see these kind of systems more in the picture, much like the Alibaba using RL agent in their platform Taobao. The results from their research shows good performance in the online community over other popular ML approaches \cite{jin2018real,shi2019virtual}. Russell and Norvig in their book \cite{russell2016artificial} comments \textit{``reinforcement Learning might be considered to encompass all of AI: an agent is placed in an environment and must learn to behave successfully therein and reinforcement learning can be viewed as a microcosm for the entire AI problem''}. Reinforcement learning is the very basis by which us humans, the most effective learning agents learn to tackle novel situations in our environment. Advances in Deep RL has paved the path further, invoking the hypothesis by David Silver that AI = RL + DL. This makes a strong case to study the effects of reinforcement learning agents on network structure, specially with the combination of homophily.